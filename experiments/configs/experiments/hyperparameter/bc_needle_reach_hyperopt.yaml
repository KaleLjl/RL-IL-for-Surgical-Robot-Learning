# BC Hyperparameter Optimization Configuration for Needle Reach
# Usage: python3 hyperopt_unified.py --algorithm bc --task needle_reach --n-trials 50

# Base algorithm configuration
algorithm: "bc"
seed: 42

# This config serves as template - hyperopt_unified.py will override these values
# during optimization based on the search spaces defined in the script

network:
  needle_reach:
    hidden_sizes: [256, 256]  # Will be optimized: [128,128], [256,256], [512,512], etc.
    activation: "relu"        # Will be optimized: ["relu", "tanh"]

training:
  needle_reach:
    epochs: 200               # Will be optimized: range [75, 300]
    batch_size: 64            # Will be optimized: [32, 64, 128]
    learning_rate: 1.0e-4     # Will be optimized: log range [1e-5, 1e-3]
    weight_decay: 1.0e-4      # Will be optimized: log range [1e-6, 1e-3]
    early_stopping_patience: 10  # Will be optimized: range [5, 20]
    early_stopping_threshold: 0.001

data:
  num_demonstrations: 100

logging:
  tensorboard: false        # Disabled during optimization for speed
  csv_logging: true
  save_freq: 40
  verbose: 0               # Minimal logging during optimization

# Optimization metadata (not used by train_unified.py)
hyperopt:
  objective: "success_rate"  # Primary metric to optimize
  direction: "maximize"
  n_trials: 50
  timeout: 7200             # 2 hours per trial max
  search_space:
    hidden_sizes: 
      type: "categorical"
      choices: [[128,128], [256,256], [512,512], [128,256,128], [256,512,256]]
    activation:
      type: "categorical" 
      choices: ["relu", "tanh"]
    learning_rate:
      type: "float"
      low: 1.0e-5
      high: 1.0e-3
      log: true
    batch_size:
      type: "categorical"
      choices: [32, 64, 128]
    weight_decay:
      type: "float" 
      low: 1.0e-6
      high: 1.0e-3
      log: true
    epochs:
      type: "int"
      low: 75
      high: 300
    early_stopping_patience:
      type: "int"
      low: 5
      high: 20