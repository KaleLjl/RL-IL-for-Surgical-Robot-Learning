# BC Hyperparameter Optimization Configuration for Peg Transfer
# Usage: python3 hyperopt_unified.py --algorithm bc --task peg_transfer --n-trials 50

# Base algorithm configuration
algorithm: "bc"
seed: 42

# This config serves as template - hyperopt_unified.py will override these values
# during optimization based on the search spaces defined in the script

network:
  peg_transfer:
    hidden_sizes: [128, 128]  # Will be optimized: [64,64], [128,128], [256,256], etc.
    activation: "relu"        # Will be optimized: ["relu", "tanh"]

training:
  peg_transfer:
    epochs: 25                # Will be optimized: range [12, 50]
    batch_size: 64            # Will be optimized: [32, 64, 128]
    learning_rate: 5.0e-5     # Will be optimized: log range [1e-6, 1e-4]
    weight_decay: 1.0e-3      # Will be optimized: log range [1e-6, 1e-3]
    early_stopping_patience: 10  # Will be optimized: range [5, 20]
    early_stopping_threshold: 0.001

data:
  num_demonstrations: 100

logging:
  tensorboard: false        # Disabled during optimization for speed
  csv_logging: true
  save_freq: 5
  verbose: 0               # Minimal logging during optimization

# Optimization metadata (not used by train_unified.py)
hyperopt:
  objective: "success_rate"  # Primary metric to optimize
  direction: "maximize"
  n_trials: 50
  timeout: 7200             # 2 hours per trial max
  search_space:
    hidden_sizes: 
      type: "categorical"
      choices: [[64,64], [128,128], [256,256], [64,128,64], [128,256,128]]
    activation:
      type: "categorical" 
      choices: ["relu", "tanh"]
    learning_rate:
      type: "float"
      low: 1.0e-6
      high: 1.0e-4
      log: true
    batch_size:
      type: "categorical"
      choices: [32, 64, 128]
    weight_decay:
      type: "float" 
      low: 1.0e-6
      high: 1.0e-3
      log: true
    epochs:
      type: "int"
      low: 12
      high: 50
    early_stopping_patience:
      type: "int"
      low: 5
      high: 20