# PPO+BC Hyperparameter Optimization Configuration for Needle Reach
# Usage: python3 hyperopt_unified.py --algorithm ppo_bc --task needle_reach --n-trials 30 --bc-model-path path/to/bc/model.zip

# Base algorithm configuration
algorithm: "ppo_bc"
seed: 42

# This config serves as template - hyperopt_unified.py will override these values
# during optimization based on the search spaces defined in the script

network:
  needle_reach:
    hidden_sizes: [256, 256]  # Will be optimized: [128,128], [256,256], [512,512]
    activation: "relu"        # Will be optimized: ["relu", "tanh"]

training:
  needle_reach:
    total_timesteps: 100000   # Will be optimized: range [50000, 150000]
    learning_rate: 3.0e-4     # Will be optimized: log range [1e-5, 1e-3]
    n_steps: 2048             # Will be optimized: [1024, 2048]
    batch_size: 64            # Will be optimized: [64, 128]
    n_epochs: 10              # Will be optimized: range [5, 15]
    gamma: 0.99               # Will be optimized: range [0.95, 0.999]
    gae_lambda: 0.95
    clip_range: 0.2           # Will be optimized: range [0.1, 0.3]
    ent_coef: 0.0             # Will be optimized: log range [1e-8, 1e-2]
    vf_coef: 0.5
    max_grad_norm: 0.5

# PPO+BC specific configuration
bc:
  bc_loss_weight:
    needle_reach: 0.02        # Will be optimized: log range [0.001, 0.1]
  bc_update_frequency: 1      # Will be optimized: range [1, 10]
  use_bc_initialization: true
  bc_model_path: null         # Will be set via --bc-model-path argument

logging:
  tensorboard: false        # Disabled during optimization for speed
  csv_logging: true
  save_freq: 10000
  verbose: 0               # Minimal logging during optimization

# Optimization metadata (not used by train_unified.py)
hyperopt:
  objective: "success_rate"  # Primary metric to optimize
  direction: "maximize"
  n_trials: 30
  timeout: 10800            # 3 hours per trial max
  requires_bc_model: true   # Indicates BC model path is required
  search_space:
    # PPO parameters (reduced ranges for efficiency)
    learning_rate:
      type: "float"
      low: 1.0e-5
      high: 1.0e-3
      log: true
    n_steps:
      type: "categorical"
      choices: [1024, 2048]
    batch_size:
      type: "categorical"
      choices: [64, 128]
    n_epochs:
      type: "int"
      low: 5
      high: 15
    gamma:
      type: "float"
      low: 0.95
      high: 0.999
    clip_range:
      type: "float"
      low: 0.1
      high: 0.3
    ent_coef:
      type: "float"
      low: 1.0e-8
      high: 1.0e-2
      log: true
    total_timesteps:
      type: "int"
      low: 50000
      high: 150000
      step: 10000
    # BC-specific parameters
    bc_loss_weight:
      type: "float"
      low: 0.001
      high: 0.1
      log: true
    bc_update_frequency:
      type: "int"
      low: 1
      high: 10