{
  "timestamp": "2025-07-10T01:02:56.017225",
  "analysis_id": 307,
  "timestep": 307000,
  "elapsed_time": 12921.092432975769,
  "algorithm": "dapg",
  "metrics": {
    "episode_reward": {
      "mean": -136.67,
      "std": 33.225609099006746,
      "min": -150.0,
      "max": -26.0,
      "count": 100
    },
    "episode_length": {
      "mean": 136.82,
      "std": 32.88476242882104,
      "min": 27,
      "max": 150
    },
    "success_rate": {
      "rate": 0.15,
      "count": 100
    },
    "policy_loss": {
      "mean": 0.0819893479347229,
      "std": 0.0,
      "trend": "stable"
    },
    "value_loss": {
      "mean": 24.46651268005371,
      "std": 0.0,
      "trend": "stable"
    },
    "bc_loss": {
      "mean": -5.160905816147219,
      "std": 0.0,
      "trend": "stable"
    }
  },
  "health_check": {
    "status": "needs_attention",
    "issues": [
      {
        "type": "high_value_loss",
        "severity": "warning",
        "message": "Value function loss is high - may need more training data"
      }
    ]
  },
  "recommendations": [
    {
      "type": "batch_size",
      "action": "increase",
      "reason": "High reward variance - consider increasing batch size",
      "priority": "medium"
    },
    {
      "type": "bc_weight",
      "action": "decrease",
      "reason": "BC loss low but poor performance - reduce BC weight",
      "priority": "high"
    }
  ],
  "warnings": []
}